import random
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler

# Custom 12 places with latitude, longitude, and distance (in float)
places = [
    {'Place_ID': 1, 'Latitude': 40.712776, 'Longitude': -74.005974, 'Name': 'Place_1'},  # New York City
    {'Place_ID': 2, 'Latitude': 40.730610, 'Longitude': -73.935242, 'Name': 'Place_2'},  # Brooklyn, NYC
    {'Place_ID': 3, 'Latitude': 40.748817, 'Longitude': -73.985428, 'Name': 'Place_3'},  # Manhattan, NYC
    {'Place_ID': 4, 'Latitude': 40.764351, 'Longitude': -73.973604, 'Name': 'Place_4'},  # Midtown, NYC
    {'Place_ID': 5, 'Latitude': 40.679356, 'Longitude': -73.974535, 'Name': 'Place_5'},  # Park Slope, Brooklyn
    {'Place_ID': 6, 'Latitude': 40.758896, 'Longitude': -73.985130, 'Name': 'Place_6'},  # Times Square
    {'Place_ID': 7, 'Latitude': 40.730610, 'Longitude': -73.999669, 'Name': 'Place_7'},  # East Village
    {'Place_ID': 8, 'Latitude': 40.692202, 'Longitude': -73.974375, 'Name': 'Place_8'},  # Downtown Brooklyn
    {'Place_ID': 9, 'Latitude': 40.7580, 'Longitude': -73.9855, 'Name': 'Place_9'},      # Midtown
    {'Place_ID': 10, 'Latitude': 40.7500, 'Longitude': -73.9800, 'Name': 'Place_10'},    # Chelsea
    {'Place_ID': 11, 'Latitude': 40.6895, 'Longitude': -74.0445, 'Name': 'Place_11'},    # Statue of Liberty
    {'Place_ID': 12, 'Latitude': 40.705627, 'Longitude': -73.9783, 'Name': 'Place_12'}   # Brooklyn Bridge Park
]

# Distance Matrix between places (in kilometers)
# You can replace this with actual distances based on your data, here it's a dummy example.
distances = np.array([
    [0, 2.1, 1.8, 3.0, 4.5, 1.2, 1.0, 3.5, 2.5, 2.8, 3.2, 4.0],
    [2.1, 0, 1.5, 2.5, 3.8, 1.0, 1.2, 3.0, 1.7, 2.3, 2.8, 3.6],
    [1.8, 1.5, 0, 1.0, 2.2, 0.5, 0.7, 2.2, 1.2, 1.5, 1.9, 2.7],
    [3.0, 2.5, 1.0, 0, 1.5, 1.0, 1.2, 1.5, 2.0, 2.3, 2.5, 3.0],
    [4.5, 3.8, 2.2, 1.5, 0, 1.5, 1.8, 2.2, 3.0, 3.5, 3.8, 4.2],
    [1.2, 1.0, 0.5, 1.0, 1.5, 0, 0.5, 1.8, 1.0, 1.2, 1.5, 2.0],
    [1.0, 1.2, 0.7, 1.2, 1.8, 0.5, 0, 1.5, 0.9, 1.0, 1.4, 1.8],
    [3.5, 3.0, 2.2, 1.5, 2.2, 1.8, 1.5, 0, 1.3, 1.5, 2.0, 2.4],
    [2.5, 1.7, 1.2, 2.0, 3.0, 1.0, 0.9, 1.3, 0, 1.4, 1.7, 2.2],
    [2.8, 2.3, 1.5, 2.3, 3.5, 1.2, 1.0, 1.5, 1.4, 0, 1.9, 2.5],
    [3.2, 2.8, 1.9, 2.5, 3.8, 1.5, 1.4, 2.0, 1.7, 1.9, 0, 1.8],
    [4.0, 3.6, 2.7, 3.0, 4.2, 2.0, 1.8, 2.4, 2.2, 2.5, 1.8, 0]
])

# Define time range for each day (9 AM to 7 PM, 1-hour intervals)
start_time = datetime(2025, 3, 21, 9, 0)  # Starting from 9 AM
end_time = datetime(2025, 3, 21, 19, 0)  # Ending at 7 PM
time_interval = timedelta(hours=1)  # 1-hour intervals

timestamps = []
node_data = []

# Generate data for each day (for N days)
N = 3  # Simulate for 3 days, you can increase this number
for day in range(N):
    current_day = start_time + timedelta(days=day)
    current_time = current_day

    while current_time <= end_time:
        for node in places:
            # Random number of people (between 50 and 200)
            people_count = random.randint(50, 200)
            
            # Random traffic condition
            traffic_condition = random.choice(['Low', 'Medium', 'High'])

            # Simulate weather conditions (for contextual advertising)
            weather_condition = random.choice(['Clear', 'Cloudy', 'Rainy'])
            temperature = random.randint(10, 35)  # Random temperature between 10°C and 35°C
            
            # Simulate ad data (for dynamic ads)
            ad_type = random.choice(['Billboard', 'Digital Screen', 'Hologram'])
            ad_engagement = random.choice([0.5, 1.0, 1.5, 2.0])  # Random engagement value
            clicks = random.randint(0, 50)
            impressions = random.randint(50, 200)
            engagement_rate = (clicks / impressions) * 100 if impressions != 0 else 0

            # Append data for the current timestamp and node
            node_data.append({
                'Timestamp': current_time,
                'Place_ID': node['Place_ID'],
                'Latitude': node['Latitude'],
                'Longitude': node['Longitude'],
                'People_Count': people_count,
                'Traffic_Condition': traffic_condition,
                'Weather_Condition': weather_condition,
                'Temperature': temperature,
                'Ad_Type': ad_type,
                'Ad_Engagement': ad_engagement,
                'Clicks': clicks,
                'Impressions': impressions,
                'Engagement_Rate (%)': engagement_rate
            })

        # Move to the next timestamp
        current_time += time_interval

# Convert to a DataFrame for easy analysis
df = pd.DataFrame(node_data)

# Save to CSV (optional)
df.to_csv('simulated_node_data.csv', index=False)

# Display the first few rows of the dataset
print(df.head())

# Now for model building (Random Forest Regressor to predict ad engagement)
X = df[['People_Count', 'Traffic_Condition', 'Temperature', 'Clicks', 'Impressions']]
X = pd.get_dummies(X, drop_first=True)  # Convert categorical variables to dummy/indicator variables

y = df['Ad_Engagement']

# Standardizing the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Build Random Forest model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predict on test data
y_pred = rf.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error: {mae}')

# Plotting the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.title('Random Forest Regression: True vs Predicted')
plt.grid(True)
plt.show()

# Feature Importance from Random Forest
importances = rf.feature_importances_
features = X.columns
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 6))
plt.bar(range(len(importances)), importances[indices])
plt.xticks(range(len(importances)), features[indices], rotation=90)
plt.title('Random Forest Feature Importances')
plt.show()
