import random
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error

# --- Dataset Generation: Placeholder for 12 custom places with latitudes and longitudes ---
# You will need to fill this list with your custom places' coordinates
locations = [
    {'Node_ID': 1, 'Latitude': 40.712776, 'Longitude': -74.005974},  # Placeholder for Node 1
    {'Node_ID': 2, 'Latitude': 40.730610, 'Longitude': -73.935242},  # Placeholder for Node 2
    {'Node_ID': 3, 'Latitude': 40.748817, 'Longitude': -73.985428},  # Placeholder for Node 3
    {'Node_ID': 4, 'Latitude': 40.764351, 'Longitude': -73.973604},  # Placeholder for Node 4
    {'Node_ID': 5, 'Latitude': 40.679356, 'Longitude': -73.974535},  # Placeholder for Node 5
    {'Node_ID': 6, 'Latitude': 40.748817, 'Longitude': -73.985428},  # Placeholder for Node 6
    {'Node_ID': 7, 'Latitude': 40.733610, 'Longitude': -73.989242},  # Placeholder for Node 7
    {'Node_ID': 8, 'Latitude': 40.748817, 'Longitude': -73.950428},  # Placeholder for Node 8
    {'Node_ID': 9, 'Latitude': 40.698776, 'Longitude': -73.945974},  # Placeholder for Node 9
    {'Node_ID': 10, 'Latitude': 40.710610, 'Longitude': -73.955242}, # Placeholder for Node 10
    {'Node_ID': 11, 'Latitude': 40.758817, 'Longitude': -73.965428}, # Placeholder for Node 11
    {'Node_ID': 12, 'Latitude': 40.768351, 'Longitude': -73.973604}, # Placeholder for Node 12
]

# --- Simulating Traffic, Ads, and People Data for Multiple Days ---
def generate_data():
    traffic_levels = ['Low', 'Medium', 'High']
    ad_types = ['Video', 'Banner', 'Interactive']
    start_time = datetime(2025, 3, 21, 9, 0)
    end_time = datetime(2025, 3, 21, 19, 0)  # 9 AM to 7 PM
    time_interval = timedelta(minutes=30)
    
    data = []
    
    current_time = start_time
    while current_time <= end_time:
        for location in locations:
            people_count = random.randint(50, 200)
            traffic_condition = random.choice(traffic_levels)
            ad_type = random.choice(ad_types)
            clicks = random.randint(5, 50)
            impressions = random.randint(100, 500)
            engagement_rate = (clicks / impressions) * 100 if impressions != 0 else 0
            # Add data point for the current time and location
            data.append({
                'Timestamp': current_time,
                'Node_ID': location['Node_ID'],
                'Latitude': location['Latitude'],
                'Longitude': location['Longitude'],
                'People_Count': people_count,
                'Traffic_Condition': traffic_condition,
                'Ad_Type': ad_type,
                'Clicks': clicks,
                'Impressions': impressions,
                'Engagement_Rate': engagement_rate
            })
        current_time += time_interval
    
    return pd.DataFrame(data)

# Generate the dataset
df = generate_data()

# --- Feature Engineering and Data Preprocessing ---
# Convert Timestamp to Hour of the Day
df['Hour'] = pd.to_datetime(df['Timestamp']).dt.hour

# Convert categorical columns to numerical values (Label Encoding)
df['Traffic_Condition'] = df['Traffic_Condition'].map({'Low': 0, 'Medium': 1, 'High': 2})
df['Ad_Type'] = df['Ad_Type'].map({'Video': 0, 'Banner': 1, 'Interactive': 2})

# Features and target variable (predict engagement rate)
X = df[['Hour', 'Traffic_Condition', 'People_Count', 'Ad_Type']]  # Features
y = df['Engagement_Rate']  # Target variable

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Scaling the Data ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- Model: Random Forest Regressor ---
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# --- Prediction ---
y_pred = model.predict(X_test_scaled)

# --- Model Evaluation: Mean Absolute Error ---
mae = mean_absolute_error(y_test, y_pred)
print(f"Mean Absolute Error (MAE): {mae}")

# --- Visualization of Actual vs Predicted Engagement Rate ---
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([0, 100], [0, 100], color='red', linestyle='--')
plt.title('Actual vs Predicted Engagement Rate')
plt.xlabel('Actual Engagement Rate')
plt.ylabel('Predicted Engagement Rate')
plt.grid(True)
plt.show()

# --- Save the Model ---
import joblib
joblib.dump(model, 'ad_visibility_model.pkl')

# --- Load the Saved Model and Predict for New Data ---
# Example: Replace with your own new data point
new_data = pd.DataFrame({
    'Hour': [12],
    'Traffic_Condition': [1],  # Medium traffic
    'People_Count': [150],
    'Ad_Type': [0]  # Video ad
})

# Scale the new data point
new_data_scaled = scaler.transform(new_data)

# Load the model
model = joblib.load('ad_visibility_model.pkl')

# Predict engagement rate for new data
predicted_engagement = model.predict(new_data_scaled)
print(f"Predicted Engagement Rate for New Data: {predicted_engagement[0]}")

